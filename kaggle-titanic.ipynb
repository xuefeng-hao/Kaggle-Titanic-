{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment preparation \n",
    " updating the required packages i.e. SageMaker Python SDK, pandas and numpy, and specifying:\n",
    "1. The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance or Studio, training, and hosting.\n",
    "2. The IAM role ARN used to give training and hosting access to your data. See the documentation for how to create these. Note: if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with the appropriate full IAM role ARN string(s).\n",
    "3. Download data from Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install sagemaker pandas numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"sagemaker/titanic\"\n",
    "role = get_execution_role()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -p ./data titanic \n",
    "import zipfile\n",
    "zFile = zipfile.ZipFile('./data/titanic.zip', 'r')\n",
    "zFile.extractall(path = './data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing: Data Understanding\n",
    "1. Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Handle table-like data and matrices\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Modelling Algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
    "\n",
    "# Modelling Helpers\n",
    "from sklearn.preprocessing import Imputer , Normalizer , scale\n",
    "from sklearn.cross_validation import train_test_split , StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualisations\n",
    "%matplotlib inline\n",
    "mpl.style.use( 'ggplot' )\n",
    "sns.set_style( 'white' )\n",
    "pylab.rcParams[ 'figure.figsize' ] = 8 , 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Setup helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms( df , variables , n_rows , n_cols ):\n",
    "    fig = plt.figure( figsize = ( 16 , 12 ) )\n",
    "    for i, var_name in enumerate( variables ):\n",
    "        ax=fig.add_subplot( n_rows , n_cols , i+1 )\n",
    "        df[ var_name ].hist( bins=10 , ax=ax )\n",
    "        ax.set_title( 'Skew: ' + str( round( float( df[ var_name ].skew() ) , ) ) ) # + ' ' + var_name ) #var_name+\" Distribution\")\n",
    "        ax.set_xticklabels( [] , visible=False )\n",
    "        ax.set_yticklabels( [] , visible=False )\n",
    "    fig.tight_layout()  # Improves appearance a bit.\n",
    "    plt.show()\n",
    "\n",
    "def plot_distribution( df , var , target , **kwargs ):\n",
    "    row = kwargs.get( 'row' , None )\n",
    "    col = kwargs.get( 'col' , None )\n",
    "    facet = sns.FacetGrid( df , hue=target , aspect=4 , row = row , col = col )\n",
    "    facet.map( sns.kdeplot , var , shade= True )\n",
    "    facet.set( xlim=( 0 , df[ var ].max() ) )\n",
    "    facet.add_legend()\n",
    "\n",
    "def plot_categories( df , cat , target , **kwargs ):\n",
    "    row = kwargs.get( 'row' , None )\n",
    "    col = kwargs.get( 'col' , None )\n",
    "    facet = sns.FacetGrid( df , row = row , col = col )\n",
    "    facet.map( sns.barplot , cat , target )\n",
    "    facet.add_legend()\n",
    "    \n",
    "def plot_correlation_map( df ):\n",
    "    corr = titanic.corr()\n",
    "    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n",
    "    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n",
    "    _ = sns.heatmap(\n",
    "        corr, \n",
    "        cmap = cmap,\n",
    "        square=True, \n",
    "        cbar_kws={ 'shrink' : .9 }, \n",
    "        ax=ax, \n",
    "        annot = True, \n",
    "        annot_kws = { 'fontsize' : 12 }\n",
    "    )\n",
    "\n",
    "def describe_more( df ):\n",
    "    var = [] ; l = [] ; t = []\n",
    "    for x in df:\n",
    "        var.append( x )\n",
    "        l.append( len( pd.value_counts( df[ x ] ) ) )\n",
    "        t.append( df[ x ].dtypes )\n",
    "    levels = pd.DataFrame( { 'Variable' : var , 'Levels' : l , 'Datatype' : t } )\n",
    "    levels.sort_values( by = 'Levels' , inplace = True )\n",
    "    return levels\n",
    "\n",
    "def plot_variable_importance( X , y ):\n",
    "    tree = DecisionTreeClassifier( random_state = 99 )\n",
    "    tree.fit( X , y )\n",
    "    plot_model_var_imp( tree , X , y )\n",
    "    \n",
    "def plot_model_var_imp( model , X , y ):\n",
    "    imp = pd.DataFrame( \n",
    "        model.feature_importances_  , \n",
    "        columns = [ 'Importance' ] , \n",
    "        index = X.columns \n",
    "    )\n",
    "    imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n",
    "    imp[ : 10 ].plot( kind = 'barh' )\n",
    "    print (model.score( X , y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_train(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Prepare data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "    load data to S3\n",
    "'''\n",
    "inputs = sess.upload_data(path=\"./data\", bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))\n",
    "\n",
    "output_location = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "print(\"training artifacts will be uploaded to: {}\".format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!mv kaggle.json ../.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
